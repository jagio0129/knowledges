To Thread or Not to Thread: An In-Depth Look at Ruby’s Execution Models(スレッドにするかしないか。Rubyの実行モデルを徹底解剖する)
===

元記事: [To Thread or Not to Thread: An In-Depth Look at Ruby’s Execution Models](https://shopify.engineering/ruby-execution-models?utm_campaign=ShopifyEng&utm_source=twitter&utm_medium=social&utm_content=1657560987)

近年、Ruby アプリケーションをスレッドサーバでデプロイすることは、標準的な手法として広く認知されるようになりました。[2022年のRuby on Railsコミュニティ調査](https://rails-hosting.com/2022/#which-rails-servers-are-you-using-in-production)によると、世界のRailsコミュニティの2,600人以上のメンバーがRailsの使用経験に関する一連の質問に回答し、Pumaなどのスレッド型Webサーバが圧倒的に人気の高いデプロイ先になっています。同様に、ジョブ プロセッサに関しても、スレッド ベースの Sidekiq がデプロイの大部分を占めているようです。

この投稿では、この実践の背後にある仕組みと理由を探り、アプリケーションでスレッドを利用すべきかどうか（そしてその数）に関して十分な情報を得た上で決断するのに役立つ知識とアドバイスを共有します。

## なぜスレッドが一般的なデフォルトなのか？

スレッドサーバーが人気を集めているのには確かにさまざまな要因がありますが、その主なセールスポイントは、メモリ使用量をあまり増やさずにアプリケーションのスループットを向上させることができる点です。スレッドとプロセスのトレードオフを十分に理解するためには、メモリ使用量を理解することが重要です。

### Webアプリケーションのメモリ使用量

概念的には、Webアプリケーションのメモリ使用量は2つの部分に分けることができます。

![](https://cdn.shopify.com/s/files/1/0779/4361/files/Image1_Resized_REM_6cc0f7b8-74db-4af2-87b3-82b01e0e40ff.png?format=webp&v=1653494057)

> Web アプリケーションのメモリ使用量には、静的メモリと処理用メモリがあります。

静的メモリは、アプリケーションを実行するために必要なすべてのデータです。Ruby VM 自体と、アプリケーションのロード時に生成されたすべての VM バイトコード、そしておそらく I18n データなどの静的 Ruby オブジェクトで構成されています。この部分は固定費のようなもので、サーバが1スレッドで動こうが10スレッドで動こうが、この部分は安定しており、読み取り専用と考えることができます。

要求処理メモリは、要求を処理するために必要なメモリ量です。そこには、データベースのクエリ結果や、レンダリングされたテンプレートの出力などがあります。このメモリは常にガベージコレクタによって解放され、再利用されており、必要な量はアプリケーションが実行するスレッドの量に正比例します。

この単純化されたモデルに基づいて、Webアプリケーションのメモリ使用量を次のように表現する。

```
processes * (static_memory + (threads * processing_memory))
```

つまり、512MiBしか利用できない場合、アプリケーションが200MiBの静的メモリを使用し、150MiBの処理メモリを必要とすると、シングルスレッド・プロセスを2つ使用すると700MiBのメモリが必要になりますが、2スレッドのシングルプロセスを使用すると500MiBしか使用せず、Heroku dynoに収まるということです。

![](https://cdn.shopify.com/s/files/1/0779/4361/files/Image2_Resized_REM_4ef0f50e-7746-44d8-9054-e22ae0adc3af.png?format=webp&v=1653494056%22)

> 2つのスレッドを持つ1つのプロセスは、2つのシングルスレッドプロセスより少ないメモリを使用します。

しかし、このモデルも他のモデルと同様、現実を単純化したものです。もう1つ複雑なレイヤーを追加することで、より現実に近づけてみましょう。コピーオンライト（CoW）です。

## コピーオンライト入門

CoWは、一般的なリソース管理手法で、ユーザーの1人が変更する必要があるまで、リソースを複製せずに共有し、その時点で実際にコピーが行われるものです。もし、変更がなければ、コピーも行われません。

70年代や80年代の古いUNIXシステムでは、プロセスをフォークすると、そのプロセスのアドレス可能なメモリ全体が新しいプロセスのアドレス空間にコピーされ、事実上メモリ使用量が2倍になりました。しかし、90年代半ば以降、すべてとは言わないまでも、ほとんどのフォーク実装は、プロセスを騙して自分だけのメモリ領域を持っていると思わせ、実際には他のプロセスと共有しているため、もはやそのようなことはない。

子プロセスがフォークされると、そのページテーブルは親のメモリページを指すように初期化されます。その後、親プロセスまたは子プロセスがこれらのページのいずれかに書き込もうとすると、オペレーティングシステムが通知され、変更される前に実際にページがコピーされます。

つまり、フォークが起こった後、子も親もこれらの共有ページに書き込みをしなければ、フォークされたプロセスは本質的に自由であるということです。

![](https://cdn.shopify.com/s/files/1/0779/4361/files/Image3_Resized_REM_4ed76103-b7d1-4177-a761-5fd24ea3e75f.png?format=webp&v=1653494056)

> Copy on Writeでは、親プロセスをフォークすることでリソースを共有することができます。

つまり、完璧な世界では、メモリ使用量の計算式は次のようになります。

```
static_memory + (processes * threads * processing_memory)
```

つまり、スレッドはプロセスに対して全く優位性がないのです。

しかし、もちろん完璧な世界ではありません。問題は、どれくらいの数の共有ページが書き込まれるかということです。これに答えるには、アプリケーションのメモリ使用量を正確に測定する方法を知る必要があります。

## メモリメトリクスの誤魔化しに注意

CoWやその他のメモリ共有技術により、アプリケーションやプロセスのメモリ使用量を測定するさまざまな方法が存在するようになりました。コンテキストによって、いくつかのメトリクスは、より適切であったり、そうでなかったりすることがあります。

### RSSがあなたの求める指標でない理由

ps などの管理ツールで最もよく表示されるメモリ指標は、RSS（Resident Set Size）です。RSS には使い道がありますが、フォークしたサーバーを扱うときには本当に誤解を招きやすいものです。100MiB のプロセスをフォークして、どのメモリ領域にも書き込まない場合、RSS は両方のプロセスが 100MiB を使用していると報告します。100MiBは2つのプロセスで共有されているため、同じメモリが2度報告されることになり、これは不正確です。

もう少し良い指標は、PSS（Proportional Set Size）です。PSSでは、共有メモリ領域のサイズは、それらを共有するプロセスの数で割られます。つまり、1回フォークされた100MBのプロセスは、実際には50MBのPSSを持っているはずです。PSSの数値をすべて足せば、実際に使用されているメモリの量がわかるので、メモリの枯渇が近いかどうかを判断するのであれば、これはすでにもっと役に立つ指標です。

Linuxでは、`cat /proc/$PID/smaps_rollup`でプロセスのメモリ使用量の詳細な内訳を得ることができます。以下は、実運用中のアプリケーションの1つであるUnicornワーカーでの表示です。

```
Rss:              771912 kB
Pss:              441856 kB
...
Shared_Clean:      18288 kB
Shared_Dirty:     315648 kB
Private_Clean:        48 kB
Private_Dirty:    437928 kB
```

親プロセスにも、

```
Rss:              508544 kB
Pss:              109398 kB
...
Shared_Clean:      14680 kB
Shared_Dirty:     411584 kB
Private_Clean:      2844 kB
Private_Dirty:     79436 kB
```

ここで、各要素の意味を紐解いてみましょう。まず、SharedとPrivateのフィールド。Sharedはその名の通り、複数のプロセスで使用されているメモリ領域の総和である。一方、プライベートメモリは、特定のプロセスに対して割り当てられ、他のプロセスとは共有されないメモリ領域です。この例では、771,912 KB のアドレス可能なメモリのうち、実際に Unicorn ワーカーが所有しているのは 437,928 KB (56.7%) だけで、残りは親プロセスから受け継いだものであることを示しています。

クリーンとダーティについては、クリーンメモリは、割り当てられたが書き込まれなかったメモリ（Rubyバイナリやさまざまなネイティブ共有ライブラリなど）である。ダーティメモリは、少なくとも1つのプロセスによって書き込まれたことのあるメモリです。親プロセスが子プロセスをフォークする前に書き込まれたものであれば、共有することができます。

## コピーオンライトの効率性の測定と改善

共有メモリがプロセスの効率を最大化する鍵であることを確認しました。ここで重要なのは、スタティック メモリが実際にどれくらい共有されているかということです。これを概算するために、ワーカーの共有メモリと親プロセスの RSS を比較します。このアプリでは 508,544 kB ですので。

```
worker_shared_mem / master_rss
>>(18288 + 315648) / 508544.0 * 100
>>65.66
```

ここでは、スタティック・メモリの約3分の2が共有されていることがわかる。

![](https://cdn.shopify.com/s/files/1/0779/4361/files/Image4_Resized_REM_7c388895-08ab-4daa-96e6-7af69959de6a.png?format=webp&v=1653494057)

> ワーカーの共有メモリと親プロセスのRSSを比較すると、このアプリのスタティックメモリの2/3が共有されていることがわかります。

RSS を見ていると、ワーカーを 1 つ追加するごとに ~750MiB かかると思いますが、実際には ~427MiB に近く、スレッドを 1 つ追加すると ~257MiB かかると考えられます。これはまだ顕著に多いのですが、最初の素朴なモデルが予測したものよりもはるかに少ないものです。

アプリケーションオーナーが CoW の効率を上げる方法はいくつかありますが、一般的なアイデアは、サーバーがフォークする前にブートプロセスの一部として可能な限り多くのものをロードすることです。このトピックは非常に広範で、それだけで1つの記事になり得ますが、ここではいくつかの簡単なポインタを紹介します。

まず最初に行うべきことは、アプリケーションを完全にロードするようにサーバを設定することです。Unicorn、Puma、Sidekiq Enterpriseはすべて、この目的のためにpreload_appオプションを持っています。それが終わったら、CoWのパフォーマンスを低下させる一般的なパターンは、クラス変数のメモ化などです。

```ruby
class SomeStuff
  def self.something
    @something ||= load_some_data
  end
end
```

このように評価が遅れると、メモリが共有されなくなり、このメソッドを最初に呼び出すリクエストの速度が低下します。単純な解決策は代わりに定数を使うことですが、それができない場合、次善の策として、ここに示すように[Railsのeager_load_namespaces](https://guides.rubyonrails.org/configuring.html#config-eager-load-namespaces)機能を活用することです。

```ruby
class SomeStuff
  def self.something
    @something ||= load_some_data
  end

  def self.eager_load!
    something
  end
end

# config/application.rb
config.before_eager_load do
  config.eager_load_namespaces << SomeStuff
end
```

さて、これらの遅延ロードされた定数を探すのが厄介なところです。Ruby の[ヒーププロファイラ (heap-profiler)](https://github.com/Shopify/heap-profiler#heap-analysis) は、このための便利なツールです。これを使うと、fork直後にヒープ全体をダンプし、いくつかのリクエストを処理した後に、プロセスがどれだけ成長し、これらの余分なオブジェクトがどこに割り当てられたかを見ることができます。

## プロセスベース・サーバーの場合

そのため、プロセスベースのサーバーを使用する際にはメモリコストが増加しますが、より正確なメモリメトリクスとCoWなどの最適化を使用してプロセス間でメモリを共有することで、これをある程度軽減することができます。しかし、メモリコストが増えるのに、なぜUnicornやResqueのようなプロセスベースのサーバーを使うのでしょうか？実はプロセスベース・サーバーには、見落としてはならない利点があるので、それを見ていきましょう。

### クリーンタイムアウトの仕組み

大規模なアプリケーションを実行していると、あるリクエストに必要以上に時間がかかるというバグに遭遇することがあります。それは、悪意ある者があなたのサービスを DOS 化するために特別に作ったものかもしれませんし、予想外に大きなデータを処理しているのかもしれません。このような場合、このリクエストをきれいに中断できることが、回復力のために最も重要です。プロセスベースのサーバはワーカープロセスを終了させ、新しいワーカープロセスをフォークしてそれを置き換えることで、リクエストをきれいに中断させることができます。

しかし、スレッドはきれいに中断することができません。スレッドは他のスレッドとミュータブルなリソースを直接共有しているので、一つのスレッドをkillしようとすると、ミューテックスやデータベース接続などのリソースを回復不可能な状態にし、他のスレッドが様々な回復不可能なエラーに遭遇する可能性があるのです。

### [Global VM Lock](https://www.speedshop.co/2020/05/11/the-ruby-gvl-and-scaling.html)遅延のブラックボックス

Ruby (および Python などの同様の制約を持つ他の言語) では、レイテンシの改善もスレッドに対するプロセスの大きな利点です。典型的なWebアプリケーションのプロセスは、2種類の作業を行います。CPU と I/O です。そのため、2つのRubyのプロセスは以下のようになります。

![](https://cdn.shopify.com/s/files/1/0779/4361/files/TestingImage5REM.png?format=webp&v=1653499651)

> Rubyアプリケーションの2つのプロセスにおけるCPUとIO。

しかし、Rubyのプロセスでは、悪名高いグローバルVMロック（GVL）のために、一度に1つのスレッドしかRubyコードを実行できず、ガベージコレクタ（GC）が起動すると、すべてのスレッドが一時停止されるのです。そのため、2つのスレッドを使用する場合、代わりに次のような図になります。

![](https://cdn.shopify.com/s/files/1/0779/4361/files/Image6_HQ_REM.png?format=webp&v=1653499920)

> Global VM Lock (GVL) は Ruby のスレッドでレイテンシーを増加させます。

そのため、2つのスレッドが同時にRubyのコードを実行する必要があるたびに、サービスの遅延が増加します。これがどの程度起こるかは、アプリケーションによって、またリクエストによって大きく異なります。考えてみれば、N個のスレッドでプロセスを完全に飽和させるためには、アプリケーションはその時間の1 / N未満をI/O待ちのために費やすだけでよいのです。つまり、2つのスレッドで50%のI/O、4つのスレッドで75%のI/O、などです。リクエストのI/OとCPUの使用は非常に予測不可能であることを考えると、2つのスレッドで75%のI/Oを行うアプリケーションは、まだ頻繁にGVLで待機することになります。

Rubyのコミュニティでは、Rubyのアプリケーションは比較的I/Oが重いと言われていますが、私の経験では、GCポーズがGVLも取得することを考えると、そうとも言い切れませんし、RubyのアプリケーションはGCでかなりの時間を過ごす傾向があると思います。

Webアプリケーションは、多くの場合、Webリクエストサイクルの中で長いI/O操作を避けるように特別に設計されています。サードパーティのAPIを呼び出したり、電子メール通知を送ったりするような、遅かったり信頼できなかったりするI/O操作は、一般にバックグラウンドのジョブキューに延期されるため、Webリクエストの残りのI/Oはほとんどが適度に速いデータベースとキャッシュのクエリーになります。その結果、アプリケーションのジョブ処理側は、ウェブ側よりもはるかにI/O集約的になる傾向があります。そのため、Sidekiqのようなジョブプロセッサーは、より高いスレッド数の恩恵をより頻繁に受けることができます。しかし、ウェブサーバであっても、スレッドを使用することは、ドルあたりのスループットとレイテンシーの間の完全に許容できるトレードオフと見なすことができます。

主な問題は、GVLによってサービスの遅延がどの程度影響を受けているかを測定する良い方法が今のところないため、サービスオーナーは暗闇の中に取り残されていることです。RubyにはGVLを計測する方法がないので、スレッド数を徐々に増やしたり減らしたりして遅延指標への影響を測るような代理的な指標しか残っていませんが、それでも十分とは言えません。

そのため、私は最近、[Ruby 3.2の機能要求と概念実証の実装をまとめ、GVL計測API](https://bugs.ruby-lang.org/issues/18339)を提供することにしました 。本当に低レベルで使いにくいAPIですが、もし採用されたら、GVLの待ち時間を正確に知るための簡単なメトリクスを公開するgemを公開する予定で、アプリケーションパフォーマンス監視サービスがそれを含むことを望んでいます。

### RactorとFibers - 銀の弾丸ではない解決策

ここ数年、Ruby コミュニティでは、スレッドに代わる他の並行処理構造として、Ractors と Fibers の実験が盛んに行われています。

Ractors は Ruby のコードを並列に実行することができ、単一の GVL を持つのではなく、各 Ractor が独自のロックを持つので、理論的にはゲームを変えることができます。しかし、Ractorはグローバルに変更可能な状態を共有できないので、Ractor間でデータベース接続プールやロガーを共有することさえできない。これは、ほとんどのライブラリを大幅にリファクタリングする必要がある、アーキテクチャ上の大きな挑戦です。間違っていることが証明されることを望みますが、Ractorが大規模なWebアプリケーションの実行単位としてすぐに使われるようになるとは思っていません。

ファイバーについては、基本的に協調的にスケジューリングされたより軽いスレッドです。ですから、前のセクションでスレッドとGVLについて述べたことは、すべてファイバーにも当てはまります。ファイバーは、バイトストリームを移動させるだけで、コードの実行にあまり時間をかけないI/O集中型のアプリケーションに非常に適していますが、数個以上のスレッドから利益を得られないアプリケーションは、ファイバーを使用しても利益を得られません。

### YJITは現状を変えるかもしれない

今はまだそうではありませんが、YJIT の登場により、将来的にスレッドサーバを稼働させる必要性が大幅に高まるかもしれません。ジャストインタイム（JIT）コンパイラは、共有できないメモリ使用量を犠牲にしてコード実行を高速化するので、RubyをJIT化するとCoW性能は低下しますが、それに比例してアプリケーションのI/O負荷も高くなります。

今のところ、YJITはささやかな速度向上しか実現していませんが、将来的に2倍程度の速度向上が可能になれば、メモリコストの増加を補うために、アプリケーション所有者はWebスレッドの数を増やすことができるようになるのは間違いないでしょう。

### 覚えておきたいポイント

最終的にプロセスベースとスレッドベースのサーバーのどちらを選ぶかは、多くのトレードオフを伴うので、最初にアプリケーションの指標を見ずにどちらかを推奨するのは無理があります。

しかし、抽象的な話として、心に留めておくべきいくつかの簡単なポイントを挙げておきます。

- CoWの恩恵をできるだけ受けるために、常にアプリケーションのプリロードを有効にしてください
- アプリケーションが最小のサービスやホスティングプロバイダーに収まる場合を除き、より小さなコンテナを多数使用するのではなく、より大きなコンテナを少数使用するようにします。たとえば、1CPU 512MiB の RAM を搭載したコンテナを4つ並べるよりも、4CPU 2GiB の RAM を搭載したコンテナを1つ並べる方が効率的です。
- コストを低く抑えることよりもレイテンシーが重要な場合、あるいはそのための十分な空きメモリがある場合は、Unicornを使用して信頼性の高いリクエストタイムアウトの恩恵を受けましょう。
  - 注意：Unicornはリクエストをバッファリングするリバースプロキシによって、遅いクライアントからの攻撃から保護する必要があります。それが問題なら、Puma はワーカーあたり 1 つのスレッドで動作するように設定できます。
- スレッドを使用する場合、アプリケーションの半分以上の時間をI/O操作の待ち時間に費やしていると確信できない限り、2つのスレッドだけで開始します。ジョブプロセッサーは、より多くの I/O 処理を行う傾向があり、レイテンシーにあまり敏感でないため、高いスレッド数の恩恵を容易に受けることができるため、これは当てはまりません。

## 今後の展望 Rubyエコシステムの今後の改善点

私たちは、プロセスベースとスレッドベースの両方のサーバーの状況を改善するために、いくつかの手段を模索しています。

まず、前述した [GVL 計測 API](https://bugs.ruby-lang.org/issues/18339) があります。これにより、アプリケーション所有者は、スループットとレイテンシーの間のトレードオフを、より多くの情報に基づき行えるようになると期待されます。これを利用して、GVL の競合がある閾値を超えたときに、並行処理を動的に調整することで自動的に背圧をかけるようにすることも可能です。

さらに、スレッド化されたウェブサーバーは、理論的には信頼性の高いリクエストタイムアウトメカニズムを実装することができます。あるリクエストに予想以上の時間がかかると、影響を受けたワーカーへのリクエスト転送を停止し、他のすべてのリクエストが完了するかタイムアウトするのを待ってから、ワーカーを殺して再フォークさせることができるのです。これは [Matthew Draper が数年前に研究したこと](https://gist.github.com/matthewd/e88dea2373b8dc688752f12ed71a841a)で、実現可能だと思われます。

そうすれば、Ruby自体のCoW性能はさらに向上する可能性があります。この目的のために、何年か前からいくつかのパッチがマージされていますが、おそらくもっとできることがあるはずです。注目すべきは、Rubyのインラインキャッシュが、一度実行されたVMバイトコードのほとんどを非共有にする原因になっていると思われることです。また、[InstagramのエンジニアリングチームがPythonのCoWパフォーマンスを改善するために行ったこと](https://instagram-engineering.com/copy-on-write-friendly-python-garbage-collection-ad6ed5233ddf)から、いくつかのインスピレーションを得ることができると思います。例えば、彼らはgc.freeze()メソッドを導入し、既存のメモリ領域がすべて共有になることをGCに指示しました。Pythonはこの情報を使って、メモリ使用に関してよりインテリジェントな決定を下します。例えば、共有領域内の空きスロットは使用しないようにします。
